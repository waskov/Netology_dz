{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agWZcm49hmI4",
        "outputId": "b5bf52e3-1e3a-4686-d740-19b6cd1b5ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.0.1\n",
            "  Downloading pyspark-3.0.1.tar.gz (204.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2 MB 35 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 17.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612243 sha256=f27ea8b1dc9d2d8291c60e377091a3a51598e6c67e2e8155e79e5bf5fb661732\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/34/fa/b37b5cef503fc5148b478b2495043ba61b079120b7ff379f9b\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.0.1 py4j==0.10.9"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as f\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local[*]\")\\\n",
        "        .appName('Home_work_spark')\\\n",
        "        .getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "id": "dkSGHLjghqTo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "73ab438e-186f-4afa-a556-a9c69c9c356a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f5f801387d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f363732e7a01:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Home_work_spark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType , BooleanType,DateType\n",
        "\n",
        "# schema = StructType() \\\n",
        "#       .add(\"new_cases\",IntegerType(),True) \\\n",
        "#       .add(\"total_cases\",IntegerType(),True) \\\n",
        "#       .add(\"iso_code\",StringType(),True) \\\n",
        "#       .add(\"location\",StringType(),True) \\\n",
        "#       .add(\"population\",IntegerType(),True) \\\n",
        "#       .add(\"date\", DateType(), True)\n",
        "\n",
        "      \n",
        "df = spark.read.csv('owid-covid-data.csv',header=True).select(\n",
        "        f.col(\"date\"),\n",
        "        f.col(\"total_cases\").cast(\"int\"),\n",
        "        f.col(\"new_cases\").cast(\"int\"),  \n",
        "        f.col(\"iso_code\").cast(\"string\"), \n",
        "        f.col(\"location\").cast(\"string\"),\n",
        "        f.col(\"population\").cast(\"int\"))\n",
        "\n",
        "df.show(1)\n",
        "\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "7Dr2lBo3hqZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c28604-9e25-4343-a8fd-26eff16b1942"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+---------+--------+-----------+----------+\n",
            "|      date|total_cases|new_cases|iso_code|   location|population|\n",
            "+----------+-----------+---------+--------+-----------+----------+\n",
            "|2020-02-24|          1|        1|     AFG|Afghanistan|  38928341|\n",
            "+----------+-----------+---------+--------+-----------+----------+\n",
            "only showing top 1 row\n",
            "\n",
            "root\n",
            " |-- date: string (nullable = true)\n",
            " |-- total_cases: integer (nullable = true)\n",
            " |-- new_cases: integer (nullable = true)\n",
            " |-- iso_code: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- population: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xIis9YzGoZQT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Выберите 15 стран с наибольшим процентом переболевших на 31 марта (в выходящем датасете необходимы колонки: iso_code, страна, процент переболевших)\n",
        "\n",
        "# вижу что есть какие-то WORLD и тд, фильтрую на 3 строке коды, т к страны состоят из 3 букв\n",
        "\n",
        "df.filter(f.col('date') == '2021-03-31').\\\n",
        "  filter(f.length(f.col('iso_code')) == 3).\\\n",
        "  select('iso_code','total_cases','location','population').\\\n",
        "  withColumn('persent', \n",
        "             df.total_cases / df.population * 100).\\\n",
        "  sort(f.col('persent').desc()).\\\n",
        "  select('iso_code','total_cases','persent').limit(15).show()\n",
        "  \n",
        "  #.repartition(1).write.csv(\"task1.1\", header = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C45Ps5xFi7lu",
        "outputId": "c3c48a15-db7c-4541-97e1-d5c38b7fd11a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+------------------+\n",
            "|iso_code|total_cases|           persent|\n",
            "+--------+-----------+------------------+\n",
            "|     AND|      12010|15.543907331909661|\n",
            "|     MNE|      91218|14.523725364693293|\n",
            "|     CZE|    1532332|14.308848404077997|\n",
            "|     SMR|       4730|13.937179562732041|\n",
            "|     SVN|     215602|10.370805779121204|\n",
            "|     LUX|      61642| 9.847342390123583|\n",
            "|     ISR|     833105| 9.625106044786802|\n",
            "|     USA|   30462210| 9.203010995860707|\n",
            "|     SRB|     600596| 8.826328557933492|\n",
            "|     BHR|     144445| 8.488860079114566|\n",
            "|     PAN|     355051| 8.228739065460761|\n",
            "|     PRT|     821722| 8.058699735120369|\n",
            "|     EST|     106424| 8.022681579659551|\n",
            "|     SWE|     804886| 7.969744347858805|\n",
            "|     LTU|     216119| 7.938864728274825|\n",
            "+--------+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Top 10 стран с максимальным зафиксированным кол-вом новых случаев за последнюю неделю марта 2021 в отсортированном порядке по убыванию\n",
        "#(в выходящем датасете необходимы колонки: число, страна, кол-во новых случаев)\n",
        "\n",
        "\n",
        "# фильтрую по датам, фильтрую чтобы были только страны с кодом в 3 символа, нахожу max в каждой локации за неделю\n",
        "# беру первые 10 стран из топа, джоин чтобы получить все строки для каждой из этих стран \n",
        "\n",
        "gff = df.filter('date between \"2021-03-24\" and \"2021-03-31\" and length(iso_code) = 3')\n",
        "gff.\\\n",
        "groupBy('location').agg(f.max(\"new_cases\").alias(\"new_cases\")).\\\n",
        "sort(f.col('new_cases').desc()).\\\n",
        "limit(10).select('location','new_cases').\\\n",
        "join(gff, on = ['location', 'new_cases']).\\\n",
        "sort(f.col(\"new_cases\").desc()).\\\n",
        "select('date','location','new_cases').show()\n",
        "\n",
        "#.repartition(1).write.csv(\"task1.2\", header = True)\n"
      ],
      "metadata": {
        "id": "saLPSdN2kXAZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6Q2NsBiatvxl"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Посчитайте изменение случаев относительно предыдущего дня в России за последнюю неделю марта 2021. \n",
        "#(например: в россии вчера было 9150 , сегодня 8763, итог: -387) \n",
        "#(в выходящем датасете необходимы колонки: число, кол-во новых случаев вчера, кол-во новых случаев сегодня, дельта)\n",
        "from pyspark.sql import Window\n",
        "\n",
        "df.filter('iso_code = \"RUS\"').filter('date between \"2021-03-24\" and \"2021-03-31\"').\\\n",
        "withColumn('before', f.lag(f.col('new_cases')).over(Window.orderBy('date'))).\\\n",
        "withColumn('diff', f.col('new_cases') - f.col ('before')).\\\n",
        "select('date','before','new_cases','diff').\\\n",
        "orderBy('date').show()\n",
        "\n",
        "#.repartition(1).write.csv(\"task1.3\", header = True)"
      ],
      "metadata": {
        "id": "VA0Q0WH3joh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349fd1d3-2c1f-4361-bbe4-7bb593e01f79"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+---------+----+\n",
            "|      date|before|new_cases|diff|\n",
            "+----------+------+---------+----+\n",
            "|2021-03-24|  null|     8769|null|\n",
            "|2021-03-25|  8769|     9128| 359|\n",
            "|2021-03-26|  9128|     9073| -55|\n",
            "|2021-03-27|  9073|     8783|-290|\n",
            "|2021-03-28|  8783|     8979| 196|\n",
            "|2021-03-29|  8979|     8589|-390|\n",
            "|2021-03-30|  8589|     8162|-427|\n",
            "|2021-03-31|  8162|     8156|  -6|\n",
            "+----------+------+---------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1mc4qgpMOCWZ"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}